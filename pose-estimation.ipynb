{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to get acclimatised to using the MediaPipe and OpenCV libraries in the main project of building a clone of DeepFit. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing dependencies\n",
    "%pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Gives us drawing utilities for rendering\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Importing the pose estimation model out of all the others\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the feed from the webcam\n",
    "# The 0 as an argument represents the laptop webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Infinite loop till key is pressed\n",
    "while cap.isOpened():\n",
    "    # ret is the return variable and frame gives us the image\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # This gives us the pop up on the screen\n",
    "    cv2.imshow('MediaPipe Feed', frame)\n",
    "    \n",
    "    # Exit condition to break when 'q' has been pressed or the screen is closed\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Releasing webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Setting up MediaPipe feed instance\n",
    "# If the detection is to be more sensitive, increase confidence. However, higher the detection sensitivity, the harder it is to maintain the state. Then leveraging as pose. \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolour image to be an RGB image from the original BGR by cv2\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Managing memory\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Making detection and storing detections in array results\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Recolouring back to BGR since cv2 requires that specific format\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render the detections using drawing utils\n",
    "        # Passing image, results.pose_landmarks and the connection between the landmarks\n",
    "        # Changing colour while we're at it\n",
    "        \n",
    "        # The first drawing spec is for landmarks and the second is for connections\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS, \n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), \n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "        \n",
    "        # print(results.pose_landmarks)\n",
    "        # print(results.pose_CONNECTIONS)\n",
    "        # mp.drawing_landmarks??\n",
    "        # mp.drawing_DrawingSpec??\n",
    "        \n",
    "        # Change frame to image to display the landmarks\n",
    "        cv2.imshow('MediaPipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Determine Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following image to understand the architecture of landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\\\" style=\"height:300px\\\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extracting landmarks into a list\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            # Don't break loop if no landmarks generated\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS, \n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), \n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "    \n",
    "        cv2.imshow('MediaPipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: 0.5246810913085938\n",
       "y: 0.4240453839302063\n",
       "z: -1.08075749874115\n",
       "visibility: 0.9997602105140686\n",
       ", x: 0.5484803915023804\n",
       "y: 0.35674914717674255\n",
       "z: -1.0285753011703491\n",
       "visibility: 0.9994945526123047\n",
       ", x: 0.5642131567001343\n",
       "y: 0.3554825186729431\n",
       "z: -1.0284526348114014\n",
       "visibility: 0.9995440244674683\n",
       ", x: 0.5789726972579956\n",
       "y: 0.3555600047111511\n",
       "z: -1.0289325714111328\n",
       "visibility: 0.9993973970413208\n",
       ", x: 0.4988871216773987\n",
       "y: 0.36008599400520325\n",
       "z: -1.040184736251831\n",
       "visibility: 0.9995719790458679\n",
       ", x: 0.4801512658596039\n",
       "y: 0.3603401780128479\n",
       "z: -1.039630651473999\n",
       "visibility: 0.9996622204780579\n",
       ", x: 0.46295270323753357\n",
       "y: 0.36232423782348633\n",
       "z: -1.039959192276001\n",
       "visibility: 0.9996099472045898\n",
       ", x: 0.5966876745223999\n",
       "y: 0.38098809123039246\n",
       "z: -0.6097792983055115\n",
       "visibility: 0.9994833469390869\n",
       ", x: 0.4361661970615387\n",
       "y: 0.3813874125480652\n",
       "z: -0.648589015007019\n",
       "visibility: 0.9998022317886353\n",
       ", x: 0.5473265051841736\n",
       "y: 0.4862700402736664\n",
       "z: -0.9192900657653809\n",
       "visibility: 0.9998353123664856\n",
       ", x: 0.48789653182029724\n",
       "y: 0.49338498711586\n",
       "z: -0.9293616414070129\n",
       "visibility: 0.9998997449874878\n",
       ", x: 0.7032261490821838\n",
       "y: 0.6799929738044739\n",
       "z: -0.3355939984321594\n",
       "visibility: 0.9994748830795288\n",
       ", x: 0.29317769408226013\n",
       "y: 0.6334467530250549\n",
       "z: -0.4263466000556946\n",
       "visibility: 0.9998326301574707\n",
       ", x: 0.7556341886520386\n",
       "y: 1.011316180229187\n",
       "z: -0.21907362341880798\n",
       "visibility: 0.5689218044281006\n",
       ", x: 0.10801850259304047\n",
       "y: 0.9282299876213074\n",
       "z: -0.35928142070770264\n",
       "visibility: 0.8429853320121765\n",
       ", x: 0.7997913956642151\n",
       "y: 1.3944642543792725\n",
       "z: -0.5484991073608398\n",
       "visibility: 0.046504907310009\n",
       ", x: -0.056839991360902786\n",
       "y: 1.1930973529815674\n",
       "z: -0.7228166460990906\n",
       "visibility: 0.25093284249305725\n",
       ", x: 0.8260593414306641\n",
       "y: 1.5029006004333496\n",
       "z: -0.6329423189163208\n",
       "visibility: 0.04234549403190613\n",
       ", x: -0.11551570892333984\n",
       "y: 1.2646560668945312\n",
       "z: -0.8322314023971558\n",
       "visibility: 0.199844092130661\n",
       ", x: 0.7912232279777527\n",
       "y: 1.5133097171783447\n",
       "z: -0.7235614657402039\n",
       "visibility: 0.06725651025772095\n",
       ", x: -0.08181531727313995\n",
       "y: 1.2826255559921265\n",
       "z: -0.9548494219779968\n",
       "visibility: 0.27008992433547974\n",
       ", x: 0.7720564603805542\n",
       "y: 1.4745200872421265\n",
       "z: -0.6034556031227112\n",
       "visibility: 0.06721307337284088\n",
       ", x: -0.05548897385597229\n",
       "y: 1.2626694440841675\n",
       "z: -0.7890770435333252\n",
       "visibility: 0.2815622389316559\n",
       ", x: 0.5881831645965576\n",
       "y: 1.4390965700149536\n",
       "z: -0.030176589265465736\n",
       "visibility: 0.0034192735329270363\n",
       ", x: 0.31748560070991516\n",
       "y: 1.4138020277023315\n",
       "z: 0.03437631577253342\n",
       "visibility: 0.0038627616595476866\n",
       ", x: 0.5673533082008362\n",
       "y: 2.0537519454956055\n",
       "z: 0.07015423476696014\n",
       "visibility: 0.0013621641555801034\n",
       ", x: 0.31084567308425903\n",
       "y: 2.0360376834869385\n",
       "z: 0.11838795244693756\n",
       "visibility: 0.000626327411737293\n",
       ", x: 0.5574394464492798\n",
       "y: 2.6091995239257812\n",
       "z: 0.7578662633895874\n",
       "visibility: 0.0002755317836999893\n",
       ", x: 0.30825573205947876\n",
       "y: 2.594405174255371\n",
       "z: 0.6187029480934143\n",
       "visibility: 6.327603477984667e-05\n",
       ", x: 0.5609902739524841\n",
       "y: 2.6943817138671875\n",
       "z: 0.7951351404190063\n",
       "visibility: 0.0002399944787612185\n",
       ", x: 0.29927024245262146\n",
       "y: 2.679525852203369\n",
       "z: 0.650255560874939\n",
       "visibility: 0.00014100091357249767\n",
       ", x: 0.5169926881790161\n",
       "y: 2.7775142192840576\n",
       "z: 0.22058138251304626\n",
       "visibility: 0.00023197119298856705\n",
       ", x: 0.3425774574279785\n",
       "y: 2.769007444381714\n",
       "z: -0.013667667284607887\n",
       "visibility: 9.738340304465964e-05\n",
       "]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out all of the landmarks in the map 'landmarks'\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.protobuf.pyext._message.RepeatedCompositeContainer'>\n"
     ]
    }
   ],
   "source": [
    "print(type(landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the length of the landmarks\n",
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "# Printing all landmarks iterating through the enumeration \n",
    "for ld in mp_pose.PoseLandmark:\n",
    "    print(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.5246810913085938\n",
       "y: 0.4240453839302063\n",
       "z: -1.08075749874115\n",
       "visibility: 0.9997602105140686"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the index of the landmark using map syntax\n",
    "# print(mp_pose.PoseLandmark.LEFT_SHOULDER.value)\n",
    "index = mp_pose.PoseLandmark.NOSE.value\n",
    "\n",
    "# Using the landmark map to access the last set from the loop\n",
    "landmarks[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.7032261490821838\n",
       "y: 0.6799929738044739\n",
       "z: -0.3355939984321594\n",
       "visibility: 0.9994748830795288"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.7556341886520386\n",
       "y: 1.011316180229187\n",
       "z: -0.21907362341880798\n",
       "visibility: 0.5689218044281006"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.7997913956642151\n",
       "y: 1.3944642543792725\n",
       "z: -0.5484991073608398\n",
       "visibility: 0.046504907310009"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the angle between three joints\n",
    "def calculateAngle(a, b, c):\n",
    "    # First, mid and end points converted to numpy arrays\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    # (y-end - y-mid, x-end - x-mid) | (y-beg - y-mid, x-beg - x-mid)\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    \n",
    "    # Converting radians to degrees\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    # Since the max angle that could possibly be between arm joins is 180\n",
    "    if angle > 180:\n",
    "        angle = 360 - angle\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the normalised coordinates:\n",
      "[0.7032261490821838, 0.6799929738044739]\n",
      "[0.7556341886520386, 1.011316180229187]\n",
      "[0.7997913956642151, 1.3944642543792725]\n",
      "\n",
      "These are the scaled coordinates coming from the webcam:\n",
      "[450 271]\n",
      "[483 404]\n",
      "[511 557]\n"
     ]
    }
   ],
   "source": [
    "# Storing the x and y values for the following joints\n",
    "shoulder = [\n",
    "    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "    landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "]\n",
    "\n",
    "elbow = [\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "        landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y\n",
    "]\n",
    "\n",
    "wrist = [\n",
    "    landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "    landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y\n",
    "]\n",
    "\n",
    "print('These are the normalised coordinates:', shoulder, elbow, wrist, sep='\\n')\n",
    "\n",
    "screenResolution = [640, 400]\n",
    "scaledShoulder = np.multiply(shoulder, screenResolution)\n",
    "scaledElbow = np.multiply(elbow, screenResolution)\n",
    "scaledWrist = np.multiply(wrist, screenResolution)\n",
    "\n",
    "print('\\nThese are the scaled coordinates coming from the webcam:', scaledShoulder.astype(int), scaledElbow.astype(int), scaledWrist.astype(int), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.58578268161358°\n"
     ]
    }
   ],
   "source": [
    "# Calculating the angle between the joints\n",
    "angle = calculateAngle(shoulder, elbow, wrist)\n",
    "\n",
    "print(angle, '°', sep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating detection code to render the angles between joints using the function declared above\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            ]\n",
    "\n",
    "            # Vertex angle\n",
    "            elbow = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y\n",
    "            ]\n",
    "\n",
    "            wrist = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y\n",
    "            ]\n",
    "            \n",
    "            # Calculate angle \n",
    "            angle = calculateAngle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Render the angles\n",
    "            # The arguments to putText() are - image, angle as string, coordinates, font, size, colour, line width and line\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                str(angle),\n",
    "                tuple(scaledShoulder.astype(int)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS, \n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), \n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "    \n",
    "        cv2.imshow('MediaPipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a Curl Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Updating detection code with logic to count curls\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Curl counter variables\n",
    "counter = 0\n",
    "state = None\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            shoulder = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "            ]\n",
    "\n",
    "            elbow = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y\n",
    "            ]\n",
    "\n",
    "            wrist = [\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y\n",
    "            ]\n",
    "            \n",
    "            # Calculate angle \n",
    "            angle = calculateAngle(shoulder, elbow, wrist)\n",
    "            \n",
    "            # Render the angles\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                str(format(angle,\".2f\")),\n",
    "                tuple(scaledShoulder.astype(int)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (255, 255, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA\n",
    "            )\n",
    "            \n",
    "            # Curl counter logic\n",
    "            if angle > 150:\n",
    "                state = 'DOWN'\n",
    "            # Checking if coming from down position into an up position so the counter isn't repeatedly incremented\n",
    "            elif angle < 30 and state == 'DOWN':\n",
    "                state = 'UP'\n",
    "                counter += 1\n",
    "                print(counter)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render the count to the screen\n",
    "        # Setting line width to -1 fills the entire box\n",
    "        cv2.rectangle(image, (0, 0), (225, 73), (245, 117, 16), -1)\n",
    "        \n",
    "        # Creating variables to better format the text on screen\n",
    "        widthPaddingSize = heightPaddingSize = 20\n",
    "        \n",
    "        # Render into the box\n",
    "        # Reps data\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            'REPS',\n",
    "            (widthPaddingSize, heightPaddingSize),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.5,\n",
    "            (0, 0, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "        # Counter\n",
    "        cv2.putText(\n",
    "            image,\n",
    "            str(counter),\n",
    "            (widthPaddingSize, 3 * heightPaddingSize),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (255, 255, 255),\n",
    "            2,\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        # State data\n",
    "        cv2.putText(\n",
    "            image, \n",
    "            'STATE', \n",
    "            (4 * widthPaddingSize, heightPaddingSize), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.5, \n",
    "            (0, 0, 0), \n",
    "            1, \n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        cv2.putText(\n",
    "            image,\n",
    "            state, \n",
    "            (4 * widthPaddingSize, 3 * heightPaddingSize), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            1, \n",
    "            (255, 255, 255), \n",
    "            1, \n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS, \n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), \n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "    \n",
    "        cv2.imshow('MediaPipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a00e68b57149134ce2b73879182c8cdd95184339958c7ea15c51bb9d3595f11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
