{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is to get acclimatised to using the MediaPipe and OpenCV libraries in the main project of building a clone of DeepFit. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Install and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.10.1)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (1.21.4)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: absl-py in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (1.2.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.20.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (21.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.2 is available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: matplotlib in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (4.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (3.0.6)\n",
      "Requirement already satisfied: setuptools-scm>=4 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (6.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from setuptools-scm>=4->matplotlib->mediapipe) (57.4.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\deshi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from setuptools-scm>=4->matplotlib->mediapipe) (1.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You should consider upgrading via the 'c:\\Users\\deshi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Installing dependencies\n",
    "%pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Gives us drawing utilities for rendering\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Importing the pose estimation model out of all the others\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the feed from the webcam\n",
    "# The 0 as an argument represents the laptop webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Infinite loop till key is pressed\n",
    "while cap.isOpened():\n",
    "    # ret is the return variable and frame gives us the image\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # This gives us the pop up on the screen\n",
    "    cv2.imshow('MediaPipe Feed', frame)\n",
    "    \n",
    "    # Exit condition to break when 'q' has been pressed or the screen is closed\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Releasing webcam\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Setting up MediaPipe feed instance\n",
    "# If the detection is to be more sensitive, increase confidence. However, higher the detection sensitivity, the harder it is to maintain the state. Then leveraging as pose. \n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolour image to be an RGB image from the original BGR by cv2\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Managing memory\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Making detection and storing detections in array results\n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Recolouring back to BGR since cv2 requires that specific format\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render the detections using drawing utils\n",
    "        # Passing image, results.pose_landmarks and the connection between the landmarks\n",
    "        # Changing colour while we're at it\n",
    "        \n",
    "        # The first drawing spec is for landmarks and the second is for connections\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS, \n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), \n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "        \n",
    "        # print(results.pose_landmarks)\n",
    "        # print(results.pose_CONNECTIONS)\n",
    "        # mp.drawing_landmarks??\n",
    "        # mp.drawing_DrawingSpec??\n",
    "        \n",
    "        # Change frame to image to display the landmarks\n",
    "        cv2.imshow('MediaPipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Determine Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following image to understand the architecture of landmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\\\" style=\"height:300px\\\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "    \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extracting landmarks into a list\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "        except:\n",
    "            # Don't break loop if no landmarks generated\n",
    "            pass\n",
    "        \n",
    "        mp_drawing.draw_landmarks(\n",
    "            image, \n",
    "            results.pose_landmarks, \n",
    "            mp_pose.POSE_CONNECTIONS, \n",
    "            mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2), \n",
    "            mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "    \n",
    "        cv2.imshow('MediaPipe Feed', image)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: 0.524431586265564\n",
       "y: 0.5351768732070923\n",
       "z: -1.3110240697860718\n",
       "visibility: 0.9994628429412842\n",
       ", x: 0.5489098429679871\n",
       "y: 0.4776526391506195\n",
       "z: -1.2467917203903198\n",
       "visibility: 0.998719334602356\n",
       ", x: 0.568610429763794\n",
       "y: 0.47938334941864014\n",
       "z: -1.2468059062957764\n",
       "visibility: 0.9990740418434143\n",
       ", x: 0.5838783383369446\n",
       "y: 0.48179343342781067\n",
       "z: -1.2471827268600464\n",
       "visibility: 0.9984603524208069\n",
       ", x: 0.4915153384208679\n",
       "y: 0.4692672789096832\n",
       "z: -1.2639482021331787\n",
       "visibility: 0.9989696741104126\n",
       ", x: 0.46769991517066956\n",
       "y: 0.46680909395217896\n",
       "z: -1.2633249759674072\n",
       "visibility: 0.9993616938591003\n",
       ", x: 0.44602447748184204\n",
       "y: 0.46680915355682373\n",
       "z: -1.26373291015625\n",
       "visibility: 0.9991019368171692\n",
       ", x: 0.6019253730773926\n",
       "y: 0.5047382116317749\n",
       "z: -0.7881370782852173\n",
       "visibility: 0.9987813234329224\n",
       ", x: 0.4142921566963196\n",
       "y: 0.4907793402671814\n",
       "z: -0.8658731579780579\n",
       "visibility: 0.9995675683021545\n",
       ", x: 0.5517038702964783\n",
       "y: 0.6016581654548645\n",
       "z: -1.1319081783294678\n",
       "visibility: 0.999460756778717\n",
       ", x: 0.4865489900112152\n",
       "y: 0.5987790822982788\n",
       "z: -1.1486607789993286\n",
       "visibility: 0.9996750950813293\n",
       ", x: 0.7311729788780212\n",
       "y: 0.8370513916015625\n",
       "z: -0.4204360842704773\n",
       "visibility: 0.9980537295341492\n",
       ", x: 0.24693627655506134\n",
       "y: 0.8251582384109497\n",
       "z: -0.6351926326751709\n",
       "visibility: 0.9991598129272461\n",
       ", x: 0.8671914339065552\n",
       "y: 1.1933602094650269\n",
       "z: -0.298505574464798\n",
       "visibility: 0.1173960268497467\n",
       ", x: 0.11240813881158829\n",
       "y: 1.261680245399475\n",
       "z: -0.5242798924446106\n",
       "visibility: 0.3833397328853607\n",
       ", x: 0.9111283421516418\n",
       "y: 1.5287052392959595\n",
       "z: -0.6903316974639893\n",
       "visibility: 0.012873371131718159\n",
       ", x: 0.12294958531856537\n",
       "y: 1.602759838104248\n",
       "z: -0.9335296750068665\n",
       "visibility: 0.04162043705582619\n",
       ", x: 0.9527983665466309\n",
       "y: 1.6380314826965332\n",
       "z: -0.7971760034561157\n",
       "visibility: 0.014203079976141453\n",
       ", x: 0.09607166796922684\n",
       "y: 1.7168982028961182\n",
       "z: -1.0653607845306396\n",
       "visibility: 0.037229254841804504\n",
       ", x: 0.9153962135314941\n",
       "y: 1.655305027961731\n",
       "z: -0.885219395160675\n",
       "visibility: 0.024988634511828423\n",
       ", x: 0.1455705761909485\n",
       "y: 1.7296385765075684\n",
       "z: -1.1769671440124512\n",
       "visibility: 0.060573775321245193\n",
       ", x: 0.8905318975448608\n",
       "y: 1.6115697622299194\n",
       "z: -0.7518905401229858\n",
       "visibility: 0.024546349421143532\n",
       ", x: 0.16064651310443878\n",
       "y: 1.679521083831787\n",
       "z: -0.9965763092041016\n",
       "visibility: 0.05600886419415474\n",
       ", x: 0.6544915437698364\n",
       "y: 1.609480619430542\n",
       "z: -0.03605659678578377\n",
       "visibility: 0.0006196716567501426\n",
       ", x: 0.35016947984695435\n",
       "y: 1.6290786266326904\n",
       "z: 0.04139529913663864\n",
       "visibility: 0.0005512169445864856\n",
       ", x: 0.6557413935661316\n",
       "y: 2.2580041885375977\n",
       "z: -0.00447221752256155\n",
       "visibility: 0.0009879892459139228\n",
       ", x: 0.3802536129951477\n",
       "y: 2.2835352420806885\n",
       "z: 0.059920698404312134\n",
       "visibility: 0.0003874772519338876\n",
       ", x: 0.6703314185142517\n",
       "y: 2.865283727645874\n",
       "z: 0.7045528888702393\n",
       "visibility: 0.0001346983917756006\n",
       ", x: 0.405428022146225\n",
       "y: 2.8744406700134277\n",
       "z: 0.5684744119644165\n",
       "visibility: 2.0000339645775966e-05\n",
       ", x: 0.6762555837631226\n",
       "y: 2.967758893966675\n",
       "z: 0.738475501537323\n",
       "visibility: 0.00010689104237826541\n",
       ", x: 0.40132054686546326\n",
       "y: 2.9802002906799316\n",
       "z: 0.5964437127113342\n",
       "visibility: 5.5684158724034205e-05\n",
       ", x: 0.6406860947608948\n",
       "y: 3.048541307449341\n",
       "z: 0.11497576534748077\n",
       "visibility: 0.00022312857618089765\n",
       ", x: 0.45899248123168945\n",
       "y: 3.0417962074279785\n",
       "z: -0.12117787450551987\n",
       "visibility: 8.903357957024127e-05\n",
       "]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out all of the landmarks in the map 'landmarks'\n",
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.protobuf.pyext._message.RepeatedCompositeContainer'>\n"
     ]
    }
   ],
   "source": [
    "print(type(landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the length of the landmarks\n",
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "# Printing all landmarks iterating through the enumeration \n",
    "for ld in mp_pose.PoseLandmark:\n",
    "    print(ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.7311729788780212\n",
       "y: 0.8370513916015625\n",
       "z: -0.4204360842704773\n",
       "visibility: 0.9980537295341492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the index of the landmark using map syntax\n",
    "# print(mp_pose.PoseLandmark.LEFT_SHOULDER.value)\n",
    "index = mp_pose.PoseLandmark.NOSE.value\n",
    "\n",
    "# Using the landmark map to access the last set from the loop\n",
    "landmarks[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.7311729788780212\n",
       "y: 0.8370513916015625\n",
       "z: -0.4204360842704773\n",
       "visibility: 0.9980537295341492"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.8671914339065552\n",
       "y: 1.1933602094650269\n",
       "z: -0.298505574464798\n",
       "visibility: 0.1173960268497467"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.9111283421516418\n",
       "y: 1.5287052392959595\n",
       "z: -0.6903316974639893\n",
       "visibility: 0.012873371131718159"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the angle between three joints\n",
    "def calculateAngle(a, b, c):\n",
    "    # First, mid and end points converted to numpy arrays\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    \n",
    "    # Converting radians to degrees\n",
    "    angle = np.abs(radians * 180.0 / np.pi)\n",
    "    \n",
    "    # Since the max angle that could possibly be between arm joins is 180\n",
    "    if angle > 180:\n",
    "        angle = 360 - angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build a Curl Counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a00e68b57149134ce2b73879182c8cdd95184339958c7ea15c51bb9d3595f11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
